---
title: "Investigating CRL bloat"
date: 2024-06-14T09:15:00Z
tags: certificates
---

Background:

- CPU usage spike
- Sudden increase in NAT gateway traffic (and costs) to port 80, no less
- Confounding:
  - Active login attack
  - Large sports events
- This particular service only hits 3 upstream (downstream?) services.

Investigation:

- recon:proc_window
- Suspicious about CRL checking (why?)
- Look in the source code: caching is commented out
- Turn it off, CPU usage drops.

More investigation:

- What's involved in making an HTTPS call to one of the endpoints?
- Debugging: getting into the pkix stuff.
- Does that use a lot of CPU?

```sh
make deps
ERL_LIBS=deps erl
```

```erlang
{ok, _} = application:ensure_all_started(hackney).

SSLOpts = [
    {verify, verify_peer},
    {versions, ['tlsv1.2']},
    {cacertfile, certifi:cacertfile()},
    {crl_check, peer},
    {crl_cache, {ssl_crl_cache, {internal, [{http, 10000}]}}},
    {customize_hostname_check, [{match_fun, public_key:pkix_verify_hostname_match_fun(https)}]}
].

Opts = [
    {ssl_options, SSLOpts},
    with_body
].

Url = "https://app-pl.prod.icore.sb-cloud.io/".
```

```
{ok, _, _, _} = hackney:request(get, Url, [], <<>>, Opts).
```

```erlang
timer:tc(fun() -> {ok, _, _, _} = hackney:request(get, Url, [], <<>>, Opts) end).
```

Weirdly, it takes ~28ms to do the request, once warmed up, even if I then disable the CRL cache. Didn't restart the BEAM
though, so maybe there _is_ some caching in there, somewhere.

Oh. Might be hackney pooling. If it's keeping the connection alive, it won't need to do the CRL check again.

```erlang
hackney_pool:get_stats(default).
```

Yep. 150ms the first time, then 25ms the next few times, note that `free_count` is 1. Wait for a bit. Then it's 200ms, and then 27ms.

I wonder if we're misusing the pool (or it's just poorly-implemented) amd that's adding latency, when considering the problems we were having. The concurrent connections were never particularly high, but maybe a timy bit of extra latency results in pool churn -- we can't reuse a connection (we have metrics for this), so we have to do a fresh CRL check.

...?

To reset the pool (to have control over the idle timeout):

```erlang
ok = hackney_pool:stop_pool(default).
```

Once that's in place, do some dbg magic...

```erlang
dbg:start().
dbg:tracer(process, {fun(Msg, _) -> io:format("~p\n", [Msg]) end, []}).
dbg:tpl(ssl_handshake, maybe_check_crl, '_', []).
dbg:p(all, c).
```

Note that you need a tracer, otherwise it doesn't bother.

This seems to cause it to hang, which is nice:

```
dbg:tracer(process, {fun(Msg, _) -> io:format("~p\n", [Msg]) end, []}).
dbg:tpl(public_key, pkix_crls_validate, '_', []).
dbg:p(all, c).
```

There's a lot of logging. Maybe figure out a shorter way to print the trace message.

I think the problem is the `~p` is causing a _lot_ of term expansion. Could just write the whole thing to a file and expand it later...

```
disk_log:open([{name, tracer}]).
disk_log:truncate(tracer).
dbg:start().
dbg:tracer(process, {fun(Msg, _) -> disk_log:log(tracer, Msg) end, []}).

dbg:tpl(ssl_crl_cache, fresh_crl, '_', [{'_', [], [{return_trace}]}]).
dbg:p(all, c).

% ...

dbg:stop_clear().
```

Is there a disk log viewer in Erlang?

```
ReadLog = fun ReadLog(Log, Continuation, Fun) ->
    case disk_log:chunk(Log, Continuation) of
        {Next, Terms} ->
            lists:foreach(Fun, Terms),
            ReadLog(Log, Next, Fun);
        eof ->
            ok
    end
end.

ReadLog(tracer, start, fun(Term) -> io:format("~p~n", [Term]) end).
```

Yeah, those `~p` are killing the formatting, but at least it's after the fact now, so no timeouts.

----

Using the hash dir variant.

```erlang
{ok, _} = application:ensure_all_started(hackney).

SSLOpts = [
    {verify, verify_peer},
    {versions, ['tlsv1.2']},
    {cacertfile, certifi:cacertfile()},
    {crl_check, peer},
    {crl_cache, {ssl_crl_hash_dir, {undefined, [{dir, "crls"}]}}},
    {customize_hostname_check, [{match_fun, public_key:pkix_verify_hostname_match_fun(https)}]}
].

Opts = [
    {ssl_options, SSLOpts},
    with_body
].

Url = "https://app-pl.prod.icore.sb-cloud.io/".

dbg:start().
dbg:tracer(process, {fun(Msg, _) -> io:format("~p\n", [Msg]) end, []}).
%dbg:tpl(ssl_crl_hash_dir, []).
dbg:tpl(file, read_file, '_', []).
dbg:p(all, c).

{ok, _, _, _} = hackney:request(get, Url, [], <<>>, Opts).
```

----

```erlang
{ok, _} = application:ensure_all_started(hackney).

SSLOpts = [
    {verify, verify_peer},
    {versions, ['tlsv1.2']},
    {cacertfile, certifi:cacertfile()},
    {crl_check, peer},
    {crl_cache, {ssl_crl_hash_dir, {undefined, [{dir, "crls"}]}}},
    {customize_hostname_check, [{match_fun, public_key:pkix_verify_hostname_match_fun(https)}]}
].

Opts = [
    {ssl_options, SSLOpts},
    with_body
].

Url = "https://app-pl.prod.icore.sb-cloud.io/".

timer:tc(fun() -> {ok, _, _, _} = hackney:request(get, Url, [], <<>>, Opts) end).
```

That takes ~500ms for a fresh TLS call, which is ... worse, somehow.

However: c_rehash needs PEM-encoded, so we used that. Maybe it takes a while to turn the PEM into DER? OTP can consume
the DER directly, so maybe that's cheaper?

52ms for the PEM decode, so not massive. Where's the 500ms being spent? Maybe in the tracing?

----

```erlang
{ok, _} = application:ensure_all_started(hackney).

SSLOpts = [
    {verify, verify_peer},
    {versions, ['tlsv1.2']},
    {cacertfile, certifi:cacertfile()},
    {crl_check, peer},
    {crl_cache, {ssl_crl_hash_dir, {undefined, [{dir, "crls"}]}}},
    {customize_hostname_check, [{match_fun, public_key:pkix_verify_hostname_match_fun(https)}]}
].

Opts = [
    {ssl_options, SSLOpts},
    with_body
].

Url = "https://app-pl.prod.icore.sb-cloud.io/".

% TODO: It's bad to call io:format from the tracer, in case of deadlock, though it's never bitten me.
Trace = fun
    ({trace, _Pid, call, {M, F, Args}}, _) when is_atom(M), is_atom(F), is_list(Args) ->
        io:format("~B: call ~s:~s/~B~n", [erlang:system_time(millisecond), M, F, length(Args)]);
    ({trace, _Pid, return_from, {M, F, Arity}, _Return}, _) when is_atom(M), is_atom(F), is_integer(Arity) ->
        io:format("~B: return from ~s:~s/~B~n", [erlang:system_time(millisecond), M, F, Arity]);
    (Msg, _) ->
        Depth = 6,
        io:format("~72P\n", [Msg, Depth])
end.
%Trace = fun(Msg, _) -> io:format("~p\n", [Msg]) end.
RT = dbg:fun2ms(fun(_) -> return_trace() end).

dbg:start().
%dbg:tracer().       % Uses ~p, which can be extremely verbose.
dbg:tracer(process, {Trace, []}).
dbg:tpl(ssl_crl_hash_dir, []).
dbg:tpl(file, read_file, '_', RT).
dbg:tpl(ssl_handshake, maybe_check_crl, '_', RT).
dbg:tpl(public_key, pkix_crls_validate, '_', RT).
dbg:tpl(ssl_crl, find_issuer, '_', RT).
dbg:p(all, c).

timer:tc(fun() -> {ok, _, _, _} = hackney:request(get, Url, [], <<>>, Opts) end).
```

```erlang
% Prevent deadlocks (not needed, in my experience)
%{ok, T} = dbg:get_tracer().
%{_, GL} = process_info(T, group_leader).
%dbg:p(GL, clear).
```

----

Right, so we can measure elapsed time by using a stack for each process. The tracer function returns mutated state, so
we can put stuff in there.

----

## Profiling

```erlang
{ok, _} = application:ensure_all_started(hackney).

SSLOpts = [
    {verify, verify_peer},
    {versions, ['tlsv1.2']},
    {cacertfile, certifi:cacertfile()},
    {crl_check, peer},
    {crl_cache, {ssl_crl_hash_dir, {undefined, [{dir, "crls"}]}}},
    {customize_hostname_check, [{match_fun, public_key:pkix_verify_hostname_match_fun(https)}]}
].

Opts = [
    {ssl_options, SSLOpts},
    with_body,
    {recv_timeout, infinity}
].

Url = "https://app-pl.prod.icore.sb-cloud.io/".

fprof:trace([start, {procs, new}]). % note: not 'all', otherwise it times out
{ok, _, _, _} = hackney:request(get, Url, [], <<>>, Opts).
fprof:trace(stop).
fprof:profile().
fprof:analyse([{dest, "fprof.analysis"}]).
```

----

Replacing the cache with a custom implementation.

```erlang
{ok, _} = application:ensure_all_started(hackney).

SSLOpts = [
    {verify, verify_peer},
    {versions, ['tlsv1.2']},
    {cacertfile, certifi:cacertfile()},
    {crl_check, peer},
    {crl_cache, {comcom_crl_cache, {db_handle, [foo, bar]}}},
    {customize_hostname_check, [{match_fun, public_key:pkix_verify_hostname_match_fun(https)}]}
].

Opts = [
    {ssl_options, SSLOpts},
    with_body
].

Url = "https://app-pl.prod.icore.sb-cloud.io/".

{ok, _, _, _} = hackney:request(get, Url, [], <<>>, Opts).
```